{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Make Dataset.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MahdiJahanbakht/cat-dog-classification-on-colab/blob/master/Make_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "2Rtv4asiNEJQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Make A Decent Dataset for our work"
      ]
    },
    {
      "metadata": {
        "id": "7-bUv1R-wvvw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this project we use the classic **Cat-Dog Classification** data, and In this notebook, I will show how to load images and use them to train our neural network. Fortunately the dataset is available through Kaggle API.\n",
        "We'll use this dataset to train a neural network that can differentiate between cats and dogs.\n",
        "\n",
        "Since we are going to use pytorch to train our network, the easiest way to load image data is with **datasets.ImageFolder** from **[torchvision](http://pytorch.org/docs/master/torchvision/datasets.html#imagefolder)**. \n",
        "We use ImageFolder like this:\n",
        "```dataset = datasets.ImageFolder('path/to/data', transform=transform)```\n",
        "where 'path/to/data' is the file path to the data directory and transform is a sequence of processing steps built with the **transforms** module from torchvision. The ImageFolder methos expects the training and test files being arranged in appropriate directories like this:\n",
        "\n",
        "```\n",
        "root/train/class name/xxx.png\n",
        "root/test/class name/xxx.png\n",
        "```\n",
        "So, in our example we should have some thing like this:\n",
        "```\n",
        "root/test/cat/xxx.png\n",
        "root/train/dog/xxx.png\n",
        "\n",
        "root/test/cat/xxx.png\n",
        "root/test/dog/xxx.png\n",
        "```\n",
        "As it is illustrated above, each class has it's own directory (cat and dog) for the images. The images are then labeled with the class taken from the directory name. Unfotunately, the original dataset from Kaggle is not foremd like this. So, we have to do this manually. In this note book I've do so.\n",
        "First, we have to mount out **google drive**"
      ]
    },
    {
      "metadata": {
        "id": "AxUzDgjHrbzp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NldH5VDWNGks",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Secon, we download the **biaiscience/dogs-vs-cats** dataset in a folder inside our drive. The argument path does so.\n",
        "```/content/drive/My Drive/ ``` is our mounted drive and ```Deep_Learning``` is our desired folder to save downloaded dataset into it."
      ]
    },
    {
      "metadata": {
        "id": "JpxlDj79VYgZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# kaggle datasets download -d biaiscience/dogs-vs-cats\n",
        "\n",
        "import kaggle\n",
        "\n",
        "kaggle.api.authenticate()\n",
        "\n",
        "kaggle.api.dataset_download_files('biaiscience/dogs-vs-cats', path='/content/drive/My Drive/Deep_Learning/', unzip=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gg-RemK5VZH1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The structure of the zip file is like\n",
        "```\n",
        "dogs-vs-cats.zip\n",
        "  - train.zip\n",
        "  - test1.zip\n",
        "```\n",
        "Inside ```train.zip``` there are many files like: ```cat.xxxx.jpg``` or  ```dog.xxxx.jpg``` and we are going to reshape this into:\n",
        "```\n",
        "Cat_Dog_data\n",
        "  -train\n",
        "    -dogs\n",
        "      dog.xxxx.jpg\n",
        "    -cats\n",
        "      cat.xxxx.jpg\n",
        "  -test\n",
        "    -dogs\n",
        "      dog.xxxx.jpg\n",
        "    -cats\n",
        "      cat.xxxx.jpg\n",
        "```\n",
        "The other zip file is ```test1.zip``` that contains files like: ```xxxx.jpg``` that does't show any classes that is of no use for us. So, we simply ignore that and construct our test set from training data manually.\n",
        "By running next block it unzips our desired data from downloaded dataset."
      ]
    },
    {
      "metadata": {
        "id": "OdX6wEIZMqLT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "base_dir = '/content/drive/My Drive/Deep_Learning/Datasets/'\n",
        "\n",
        "source_dir = base_dir + 'dogs-vs-cats'\n",
        "dest_dir = base_dir + 'Cat_Dog_data/'\n",
        "\n",
        "zipfile.ZipFile(source_dir + '.zip').extractall(source_dir)\n",
        "# zipfile.ZipFile(source_dir + '/test.zip').extractall(source_dir + '/test')\n",
        "zipfile.ZipFile(source_dir + '/train.zip').extractall(source_dir + '/train')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8SqToz9MNHLR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The ```make_dataset(source_dir, dest_dir, test_portion=0.2)``` function does the desired work. ```tets_portion``` argument indicatest the portion of whole dataset to be used as test data. We assume there are even number of cat/dog images in the traning data and make test data by gathering first ```test_portion/[number of classes] * [size of train data]``` images from each class. By doing so we have a test dataset with the size of  ```test_portion``` percent of whole traning data, and keeping the balance between each classes simultaneously.\n"
      ]
    },
    {
      "metadata": {
        "id": "oYAqp12jMiR6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_dataset(source_dir, dest_dir, test_portion=0.2):\n",
        "    source_dir = source_dir + '/train/'\n",
        "\n",
        "    dirs = {'train_cats': 'train/cats/',\n",
        "            'train_dogs': 'train/dogs/',\n",
        "            'test_cats': 'test/cats/',\n",
        "            'test_dogs': 'test/dogs/'}\n",
        "\n",
        "    for addr in dirs.values():\n",
        "        dest = dest_dir + addr\n",
        "        os.makedirs(dest, exist_ok=True)\n",
        "\n",
        "    files = os.listdir(source_dir)\n",
        "    test_size = int(len(files) * test_portion/2)  # There are almost equal number of cat and dog images\n",
        "\n",
        "    # move and replace if exists\n",
        "    cat_cnt = 0\n",
        "    dog_cnt = 0\n",
        "    for f in files:\n",
        "        if f.startswith(\"cat\") or f.startswith(\"Cat\"):\n",
        "            if cat_cnt <= test_size:\n",
        "                cat_cnt += 1\n",
        "                shutil.move(source_dir + f, dest_dir + dirs.get('test_cats') + f)\n",
        "            else:\n",
        "                shutil.move(source_dir + f, dest_dir + dirs.get('train_cats') + f)\n",
        "\n",
        "        if f.startswith(\"dog\") or f.startswith(\"Dog\"):\n",
        "            if dog_cnt <= test_size:\n",
        "                dog_cnt += 1\n",
        "                shutil.move(source_dir + f, dest_dir + dirs.get('test_dogs') + f)\n",
        "            else:\n",
        "                shutil.move(source_dir + f, dest_dir + dirs.get('train_dogs') + f)\n",
        "                \n",
        "make_dataset(source_dir,dest_dir,0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TBt5NYRnNIHz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Garbage Collection\n",
        "After creating our dataset, it is time to get rid of space-consuming useless data :)"
      ]
    },
    {
      "metadata": {
        "id": "Yh90G1ViK4rs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "shutil.rmtree(source_dir)\n",
        "os.remove(source_dir + '.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yrV0n3E6QqKg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
