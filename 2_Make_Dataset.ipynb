{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_Make Dataset.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MahdiJahanbakht/cat-dog-classification-on-colab/blob/master/2_Make_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "2Rtv4asiNEJQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Make A Decent Dataset for our work"
      ]
    },
    {
      "metadata": {
        "id": "7-bUv1R-wvvw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this project we use the classic **Cat-Dog Classification** data, and In this notebook, I will show how to load images and use them to train our neural network. Fortunately the dataset is available through Kaggle API.\n",
        "We'll use this dataset to train a neural network that can differentiate between cats and dogs.\n",
        "\n",
        "Since we are going to use pytorch to train our network, the easiest way to load image data is with **datasets.ImageFolder** from **[torchvision](http://pytorch.org/docs/master/torchvision/datasets.html#imagefolder)**. \n",
        "We use ImageFolder like this:\n",
        "`dataset = datasets.ImageFolder('path/to/data', transform=transform)`\n",
        "where `'path/to/data'` is the file path to the data directory and transform is a sequence of processing steps built with the **transforms** module from torchvision. The ImageFolder methos expects the training and test files being arranged in appropriate directories like this:\n",
        "\n",
        "```\n",
        "root/train/class name/xxx.png\n",
        "root/test/class name/xxx.png\n",
        "```\n",
        "So, in our example we should have some thing like this:\n",
        "```\n",
        "root/test/cat/xxx.png\n",
        "root/train/dog/xxx.png\n",
        "\n",
        "root/test/cat/xxx.png\n",
        "root/test/dog/xxx.png\n",
        "```\n",
        "As it is illustrated above, each class has it's own directory (cat and dog) for the images. The images are then labeled with the class taken from the directory name. Unfotunately, the original dataset from Kaggle is not foremd like this. So, we have to do this manually. In this note book I've do so.\n",
        "First, we have to mount our **google drive**"
      ]
    },
    {
      "metadata": {
        "id": "jFnQxzHjMYg9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If it is your first time to run this code, you have to do as the following:\n",
        "* First run the block\n",
        "* By doing so, it will appear a link in the output. Click on it\n",
        "* Then, choose your account and in the next window allow **Google Drive File Stream** to do what ever it wants :)\n",
        "* In the next page copy the verification code provided for you in the box that has been appeared below the aforementioned link in the output and press **Enter**\n",
        "This would do the trick and mount your drive at `/content/drive`."
      ]
    },
    {
      "metadata": {
        "id": "o5bSat7xYJVD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Mount Google Drive"
      ]
    },
    {
      "metadata": {
        "id": "AxUzDgjHrbzp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Moun Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NldH5VDWNGks",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Secon, we download the **biaiscience/dogs-vs-cats** dataset in a folder inside our drive. The argument `path` does so.\n",
        "`/content/drive/My Drive/` is our mounted drive's root directory and `Deep_Learning` is our desired folder to save downloaded dataset into it."
      ]
    },
    {
      "metadata": {
        "id": "0eGTeE9CYEvc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Download data"
      ]
    },
    {
      "metadata": {
        "id": "JpxlDj79VYgZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# kaggle datasets download -d biaiscience/dogs-vs-cats\n",
        "\n",
        "import kaggle\n",
        "\n",
        "kaggle.api.authenticate()\n",
        "\n",
        "kaggle.api.dataset_download_files('biaiscience/dogs-vs-cats', path='/content/drive/My Drive/Deep_Learning/', unzip=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gg-RemK5VZH1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The structure of the zip file is like\n",
        "```\n",
        "dogs-vs-cats.zip\n",
        "  - train.zip\n",
        "  - test1.zip\n",
        "  - sampleSubmission.csv\n",
        "```\n",
        "Inside `train.zip` there are many files like: `cat.xxxx.jpg` or  `dog.xxxx.jpg` and we are going to reshape this into:\n",
        "```\n",
        "Cat_Dog_data\n",
        "  -train\n",
        "    -cat\n",
        "      cat.xxxx.jpg\n",
        "    -dog\n",
        "      dog.xxxx.jpg\n",
        "  -test\n",
        "    -cat\n",
        "      cat.xxxx.jpg\n",
        "    -dog\n",
        "      dog.xxxx.jpg\n",
        "```\n",
        "The other zip file is `test1.zip` that contains files like: `xxxx.jpg` that does't show any classes that is of no use for us. So, we simply ignore that and construct our test set from training data manually.\n",
        "By running next block it unzips our desired data from downloaded dataset."
      ]
    },
    {
      "metadata": {
        "id": "h0_BmGy5X-yM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Unzip dataset\n",
        ">**Caution:** Google Drive operations can** time out** when the** number of files or subfolders in a folder grows too large**. If thousands of items are directly contained in the top-level** \"My Drive\"** folder then mounting the drive will likely time out. Repeated attempts may eventually succeed as failed attempts cache partial state locally before timing out. If you encounter this problem, try moving files and folders directly contained in **\"My Drive\"** into sub-folders. A similar problem can occur when reading from other folders after a successful `drive.mount()`. Accessing items in any folder containing many items can cause errors like `OSError: [Errno 5] Input/output error`. Again, you can fix this problem by moving directly contained items into sub-folders.  \n",
        "**Note** that \"deleting\" files or subfolders by moving them to the Trash** may not be enough**; if that doesn't seem to help, make sure to also** Empty your Trash**.[Link](https://research.google.com/colaboratory/faq.html#drive-timeout)"
      ]
    },
    {
      "metadata": {
        "id": "OdX6wEIZMqLT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "base_dir = '/content/drive/My Drive/Deep_Learning/Datasets/'\n",
        "\n",
        "source_dir = base_dir + 'dogs-vs-cats'\n",
        "dest_dir = base_dir + 'Cat_Dog_data/'\n",
        "\n",
        "# Unzip downloaded dataset in proper subdirectories\n",
        "zipfile.ZipFile(source_dir + '.zip').extractall(source_dir)\n",
        "# zipfile.ZipFile(source_dir + '/test.zip').extractall(source_dir + '/test')\n",
        "zipfile.ZipFile(source_dir + '/train.zip').extractall(source_dir + '/train')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8SqToz9MNHLR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The `make_dataset(source_dir, dest_dir, test_portion=0.2)` function does the desired work. `tets_portion` argument indicates the portion of whole dataset to be used as test data. We assume there are even number of cat/dog images in the traning data, and make test data by gathering first `(test_portion/[number of classes] * [size of train data])` images from each class. By doing so we have a test dataset with the size of  `test_portion` percent of whole traning data, while keeping the balance between each classes simultaneously.\n"
      ]
    },
    {
      "metadata": {
        "id": "3RaSOiiMYN3W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Structure data in the desired format"
      ]
    },
    {
      "metadata": {
        "id": "oYAqp12jMiR6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_dataset(source_dir, dest_dir, test_portion=0.2):\n",
        "    source_dir = source_dir + '/train/'\n",
        "\n",
        "    # destination dirs dictionary\n",
        "    dirs = {'train_cats': 'train/cat/',\n",
        "            'train_dogs': 'train/dog/',\n",
        "            'test_cats': 'test/cat/',\n",
        "            'test_dogs': 'test/dog/'}\n",
        "    # create dest folders\n",
        "    for addr in dirs.values():\n",
        "        dest = dest_dir + addr\n",
        "        os.makedirs(dest, exist_ok=True)\n",
        "    \n",
        "    files = os.listdir(source_dir)\n",
        "    test_size = int(len(files) * test_portion/2)  # There are almost equal number of cat and dog images\n",
        "\n",
        "    # move and replace if exists\n",
        "    cat_cnt = 0\n",
        "    dog_cnt = 0\n",
        "    for f in files:\n",
        "        if f.startswith(\"cat\") or f.startswith(\"Cat\"):\n",
        "            if cat_cnt <= test_size:\n",
        "                cat_cnt += 1\n",
        "                shutil.move(source_dir + f, dest_dir + dirs.get('test_cats') + f)\n",
        "            else:\n",
        "                shutil.move(source_dir + f, dest_dir + dirs.get('train_cats') + f)\n",
        "\n",
        "        if f.startswith(\"dog\") or f.startswith(\"Dog\"):\n",
        "            if dog_cnt <= test_size:\n",
        "                dog_cnt += 1\n",
        "                shutil.move(source_dir + f, dest_dir + dirs.get('test_dogs') + f)\n",
        "            else:\n",
        "                shutil.move(source_dir + f, dest_dir + dirs.get('train_dogs') + f)\n",
        "                \n",
        "make_dataset(source_dir,dest_dir,0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TBt5NYRnNIHz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Garbage Collection\n",
        "After creating our dataset, it is time to get rid of space-consuming now useless data :)"
      ]
    },
    {
      "metadata": {
        "id": "Yh90G1ViK4rs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "shutil.rmtree(source_dir)\n",
        "os.remove(source_dir + '.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yrV0n3E6QqKg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}