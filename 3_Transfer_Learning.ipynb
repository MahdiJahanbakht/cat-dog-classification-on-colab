{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_Transfer_Learning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MahdiJahanbakht/cat-dog-classification-on-colab/blob/master/3_Transfer_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "lKq1hTqUzDmf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Learn to beat cat-dog discrimination problem :)\n",
        "In this notebook I provided you with the code that does the transfer learning on a pre-trained network to train a model that solves the cat-dog classification problem. We will use a resnet network trained on  [ImageNet](http://www.image-net.org/) [available from torchvision](http://pytorch.org/docs/0.3.0/torchvision/models.html).  \n",
        ">**Hint:** imageNet is a massive dataset with over 1 million labeled images in 1000 categories. It's used to train deep convolutional neural networks.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "iUpA27IwOrcB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " >**Note:**\n",
        "If you want to benefit from the googl's amazing free **Tesla K80** gpu, first check that you are actually using **gpu supporting ** **Colab** note book.  \n",
        "To do so click on `Runtime>Change runtime type` then select **Python3** from `[Runtime Type]` and **GPU** from `[Hardware accelerator]`."
      ]
    },
    {
      "metadata": {
        "id": "18KLIc6-P9VD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "First, we have to mount  our **google drive**.  \n",
        "If it is your first time to run this code, you have to do as the following:\n",
        "* First run the block\n",
        "* By doing so, it will appear a link in the output. Click on it\n",
        "* Then, choose your account and in the next window allow **Google Drive File Stream** to do what ever it wants :)\n",
        "* In the next page copy the verification code provided for you in the box that has been appeared below the aforementioned link in the output and press **Enter**\n",
        "This would do the trick and mount your drive at `/content/drive`."
      ]
    },
    {
      "metadata": {
        "id": "hm-jIo34Y-1R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Mount Google Drive"
      ]
    },
    {
      "metadata": {
        "id": "hRCjMrcacWL9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kPXDMWCGSs9e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Check if data is accessible"
      ]
    },
    {
      "metadata": {
        "id": "B2vO1TEykWE9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataDir = '/content/drive/My Drive/Deep_Learning/Datasets/Cat_Dog_data'\n",
        "!ls '$dataDir'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xMy6MrVjUMSN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Installing Pytorch\n",
        "The code for installing the latest stable release of **pytorch** and **torchvision** on **Linux** system with **python >= 3.6** and **cuda 9.0** using **pip** is as follows([Link](https://pytorch.org/))\n",
        "In colab the code that pytorch site suggets is slightly different. It is using `pip`, and`-q` is required to install packages in Colab Vm"
      ]
    },
    {
      "metadata": {
        "id": "bV1hkX-XUJuB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q torch torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5_2yNvJnTn1u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Check **GPU** settings"
      ]
    },
    {
      "metadata": {
        "id": "ax3MlZ2zToPV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# Check wether cuda is available or not\n",
        "print('cuda availability:',torch.cuda.is_available())\n",
        "# Get device name\n",
        "print('device name:',torch.cuda.get_device_name(0))\n",
        "# Gets the the major and minor cuda capability of the device\n",
        "print('cuda capability:',torch.cuda.get_device_capability(torch.cuda.current_device()))\n",
        "# Check the current GPU memory usage by \n",
        "# tensors in bytes for a given device(should be zero if nothing is running)\n",
        "print('allocated memory:',torch.cuda.memory_allocated())\n",
        "# Check the current GPU memory managed by the\n",
        "# caching allocator in bytes for a given device(should be zero if nothing is running)\n",
        "print('cached memory:',torch.cuda.memory_cached())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YBZ1TYcnXM83",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In order to release cache and freeup some memory you can use this code"
      ]
    },
    {
      "metadata": {
        "id": "tHzAdQJFXVkW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Releases all unoccupied cached memory currently held by\n",
        "# the caching allocator so that those can be used in other\n",
        "# GPU application and visible in nvidia-smi\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zZ4cOKV3XCme",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Import Required Libraries"
      ]
    },
    {
      "metadata": {
        "id": "QLLoweMaK7wZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# import helper\n",
        "\n",
        "from collections import OrderedDict\n",
        "import time\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sAY8aO4LQHB7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Make transforms"
      ]
    },
    {
      "metadata": {
        "id": "tyVRBpR3ZTeb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Most of the torchvision's pretrained models require the input to be 224x224 images. Also, we'll need to match the normalization used when the models were trained. Each color channel was normalized separately, the means are [0.485, 0.456, 0.406] and the standard deviations are [0.229, 0.224, 0.225]. [Link](https://pytorch.org/docs/0.3.0/torchvision/models.html#id5)"
      ]
    },
    {
      "metadata": {
        "id": "HSygQoyiLAaR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "baseDir = '/content/drive/My Drive/Deep_Learning/'\n",
        "dataDir = baseDir + 'Datasets/Cat_Dog_data/'\n",
        "runDir = baseDir + 'Cat_Dog_run/'\n",
        "\n",
        "# we used batch size of 64 images for batch learning\n",
        "batch_size = 64\n",
        "\n",
        "# For traing data we used Data Augmentation of the form of transforms that\n",
        "# randomly rotate, scale and crop, then flip images\n",
        "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
        "                                       transforms.RandomResizedCrop(224),\n",
        "                                       transforms.RandomHorizontalFlip(),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                            [0.229, 0.224, 0.225])])\n",
        "\n",
        "# For test data we did'nt use any form of Data Augmentation and just used\n",
        "# resize and center crop to adjust our images for input\n",
        "test_transforms = transforms.Compose([transforms.Resize(255),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                           [0.229, 0.224, 0.225])])\n",
        "# Define train and test folders located on google drive\n",
        "trainset = datasets.ImageFolder(dataDir+'train', transform=train_transforms)\n",
        "testset = datasets.ImageFolder(dataDir+'test',transform=test_transforms)\n",
        "\n",
        "# Define batch loaders\n",
        "trainloader = torch.utils.data.DataLoader(trainset,batch_size=batch_size,shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C7v1gOtBcJue",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model Construction\n",
        "In this block we define our model. To do thar we first download a pre-trained model from the models available through **torchvision**. Then, freeze all the trained weights and just replace the classification layer, and train just that layer's weights.  \n",
        "Here we used **ResNet50** that is not a very big network, compared to others. if you print the model,  there is a **fc** layer at the end that works as classifier. We just replace that layer with our personalized classifier.  \n",
        "Something to remember is that fc layers input is 2048 in size, and it's output is of the size 1000 that is a require ment of **Imagenet** (that has 1000 classe).  \n",
        "`(fc): Linear(in_features=2048, out_features=1000, bias=True)`  \n",
        "We changed that to only 2, because we just have two classes (cat and dog)"
      ]
    },
    {
      "metadata": {
        "id": "jEV0EZSmfHGq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ">**Caution:** If you plan to use **CPU/GPU**, you should move your model and all the inputls and labels to cpu or gpu accordingly. the default is cpu. To do that you can use `.to()` method of torch tensors."
      ]
    },
    {
      "metadata": {
        "id": "UzXRF1z3JR9b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Use Gpu if it's available\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Download pre-trained model\n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "# Freeze parameters so we don't backprop through them\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Design our desired classification layer\n",
        "# LogSofmax goes with NLLLoss\n",
        "classifier = nn.Sequential(nn.Linear(2048,512),\n",
        "                          nn.ReLU(),\n",
        "                          nn.Dropout(p=0.2),\n",
        "                          nn.Linear(512,2),\n",
        "                          nn.LogSoftmax(dim=1))\n",
        "model.fc = classifier\n",
        "\n",
        "# Define cost function aas the negative log likelihood loss. It is useful to train a classification problem with C classes\n",
        "criterion = nn.NLLLoss()\n",
        "# Adam optimizer with learning rate of 0.003\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=0.003)\n",
        "# Mode our model to the selected device above\n",
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "52Mgo0rzxJIs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Learn To correctly classify adorable creatures :D"
      ]
    },
    {
      "metadata": {
        "id": "kn5ArJIuJcs6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define our epochs\n",
        "epochs = 2\n",
        "# Is used in resume Learning(Next Notebook)\n",
        "start_epoch = 0\n",
        "# To count how many steps we gone so far\n",
        "steps = 0\n",
        "# Trach training loss\n",
        "training_loss = 0\n",
        "# Save checkpoint every n steps to keep track of our models\n",
        "save_freq = 5\n",
        "\n",
        "train_losses, test_losses = [], []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # Load next batch\n",
        "    for inputs, labels in trainloader: \n",
        "        steps += 1\n",
        "        # Move input and label tensors to the default device\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        \n",
        "        # Very important. to clear gradients of previous step   \n",
        "        optimizer.zero_grad()\n",
        "        # Do the forward pass\n",
        "        logps = model.forward(inputs)\n",
        "        # Calculate cost function\n",
        "        loss = criterion(logps, labels)\n",
        "        # Compute gradients\n",
        "        loss.backward()\n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Sum up all the costs\n",
        "        training_loss += loss.item()\n",
        "        \n",
        "        ##################### Evaluation #######################\n",
        "        if steps % save_freq == 0:\n",
        "            eval_loss = 0\n",
        "            accuracy = 0\n",
        "            # Do not update weights in evaluation mode and bypass dropout\n",
        "            model.eval()\n",
        "            # Do not compute gradients. Speeds up the algorithm alot\n",
        "            with torch.no_grad():\n",
        "                # Load test data\n",
        "                for inputs, labels in testloader:\n",
        "                    # Move test tensors to device\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    # Do the forward pass\n",
        "                    logps = model.forward(inputs)\n",
        "                    # Compute cost\n",
        "                    batch_loss = criterion(logps, labels)\n",
        "                    # Sum up all the costs\n",
        "                    eval_loss += batch_loss.item()\n",
        "                    \n",
        "                    # Calculate accuracy. As you may remember we done LogSoftmax\n",
        "                    # in the last layer. So, to actual probabolities we should\n",
        "                    # calculate exp of output values\n",
        "                    ps = torch.exp(logps)\n",
        "                    # Select the best class\n",
        "                    top_p, top_class = ps.topk(1, dim=1)\n",
        "                    # Reshape our labels to match top_class shape\n",
        "                    equals = top_class == labels.view(*top_class.shape)\n",
        "                    # Change the type of equals to float tensor\n",
        "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "            # Keep track of train and test losses for each batch\n",
        "            mean_train_loss = training_loss/save_freq\n",
        "            mean_eval_loss = eval_loss/len(testloader)\n",
        "            mean_acc = accuracy/len(testloader)\n",
        "            \n",
        "            train_losses.append(mean_train_loss)\n",
        "            test_losses.append(mean_eval_loss)\n",
        "            \n",
        "            print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
        "                  f\"Train loss: {mean_train_loss:.3f}.. \"\n",
        "                  f\"Test loss: {mean_eval_loss:.3f}.. \"\n",
        "                  f\"Test accuracy: {mean_acc:.3f}\")\n",
        "            \n",
        "            # Save chechpoint\n",
        "            # A checkpoint is a python dictionary that typically includes the following\n",
        "            # The network structure: input and output sizes and Hidden layers to be able to reconstruct the model at loading time\n",
        "            # The model state dict : includes parameters of the network layers that is learned during training, \n",
        "            # The optimizer state dict : In case you are saving the latest checkpoint to continue training later, you need to save the optimizer’s state as well\n",
        "            # Additional info: You may need to store additional info, like number of epochs and your class to index mapping in your checkpoint\n",
        "            \n",
        "            checkpoint = {'model': classifier,\n",
        "                          'epoch': epoch + start_epoch,\n",
        "                          'state_dict': model.state_dict(),\n",
        "                          'optimizer' : optimizer.state_dict(),\n",
        "                          'train_loss': mean_train_loss,\n",
        "                          'test_loss': mean_eval_loss,\n",
        "                          'accuracy' : mean_acc}\n",
        "\n",
        "            torch.save(checkpoint, runDir + 'acc-{:.3f}_loss-{:.3f}_epoch-{}_checkpoint.pth.tar'.format(mean_acc, mean_eval_loss, epoch))\n",
        "\n",
        "            # Clear train losses\n",
        "            training_loss = 0\n",
        "            # change bach to learning mode\n",
        "            model.train()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DmNoxTtbJcyi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.plot(train_losses, label = 'Train loss')\n",
        "plt.plot(test_losses, label = 'Test loss')\n",
        "plt.legend(frameon = False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}